{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/clairegong/Downloads/ACV Project\r\n"
     ]
    }
   ],
   "source": [
    "!cd '/Users/clairegong/Downloads/ACV Project'\n",
    "!pwd\n",
    "root = '/Users/clairegong/Downloads/ACV Project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from celeba import CelebA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 218, 178])\n"
     ]
    }
   ],
   "source": [
    "#check private data size are also aligned, no need to resize\n",
    "private_set = datasets.ImageFolder(root, transform=transforms.ToTensor())\n",
    "private_loader = torch.utils.data.DataLoader(private_set, shuffle=False, batch_size=32)\n",
    "img, lb = iter(private_loader).next()\n",
    "print(img.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "#1. all mages are already aligned to 218*178;\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = CelebA(\n",
    "    root,\n",
    "    'train600.txt',\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "#         transforms.Resize((178,178)),\n",
    "#         transforms.CenterCrop((178,178)),\n",
    "        transforms.RandomResizedCrop(178, scale=(0.8,1.0)),# should not cut many info for multi label classification\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "val_dataset = CelebA(\n",
    "    root,\n",
    "    'val200.txt',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((178,178)),\n",
    "#         transforms.CenterCrop((178,178)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "test_dataset = CelebA(\n",
    "    root,\n",
    "    'test200.txt',\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((178,178)),\n",
    "#         transforms.CenterCrop((178,178)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0537, -0.0324, -0.0333])\n",
      "tensor([0.3751, 0.3507, 0.3415])\n"
     ]
    }
   ],
   "source": [
    "def check_normalize(train_loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for images, _ in test_loader:\n",
    "        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "    mean /= len(train_loader.dataset)\n",
    "    std /= len(train_loader.dataset)\n",
    "    print(mean)\n",
    "    print(std)\n",
    "check_normalize(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_random_image(loader):\n",
    "    img, label = next(iter(loader))\n",
    "    idx = randint(0,loader.batch_size-1)\n",
    "    img = np.transpose(img[idx].squeeze(),(1,2,0))\n",
    "    print(img.size())\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_image(train_loader)\n",
    "show_random_image(val_loader)\n",
    "show_random_image(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet18: freeze conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_pt = models.resnet18(pretrained=True)\n",
    "in_size = model_pt.fc.in_features#512->1000 in-out size\n",
    "\n",
    "#freeze pretrained parameters\n",
    "for param in model_pt.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#we need 512->2 out size\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model_pt.fc = nn.Sequential(nn.Dropout(p=0.2),nn.Linear(in_size,256), nn.ReLU(inplace=True), nn.Linear(256,40))\n",
    "model_pt.fc = nn.Linear(in_size,40)\n",
    "model_pt = model_pt.to(device)\n",
    "\n",
    "#check model paramters flexbility\n",
    "print(model_pt.conv1.weight.requires_grad)\n",
    "\n",
    "# checkpoint0 = torch.save(model_pt.state_dict(),'checkpoint0.pth')\n",
    "state_dict0 = copy.deepcopy(model_pt.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_pt = models.resnet18(pretrained=True)\n",
    "in_size = model_pt.fc.in_features#512->1000 in-out size\n",
    "\n",
    "#freeze pretrained parameters\n",
    "for param in model_pt.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#Parameters of newly constructed modules have requires_grad=True by default\n",
    "\n",
    "\n",
    "# model_pt.fc = nn.Sequential(nn.Dropout(p=0.2),nn.Linear(in_size,512), \\\n",
    "#                             nn.Dropout(p=0.2),nn.ReLU(inplace=True), nn.Linear(512,40))\n",
    "\n",
    "model_pt.fc = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(in_size,40))\n",
    "model_pt = model_pt.to(device)\n",
    "\n",
    "#check model paramters flexbility\n",
    "print(model_pt.conv1.weight.requires_grad)\n",
    "\n",
    "# checkpoint0 = torch.save(model_pt.state_dict(),'checkpoint0.pth')\n",
    "state_dict0 = copy.deepcopy(model_pt.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_pt.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### (optional)sklearn multi class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##sklearn accuracy for multi class is by sample, only all correct class prediction for a sample is True\n",
    "x = torch.Tensor([[0,1,1,0],[1,1,1,1]])\n",
    "print('x \\n',x)\n",
    "y = torch.Tensor([[0,1,0,0],[1,1,1,1]])\n",
    "print('y \\n',y)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(x,y)\n",
    "print('sklearn accuracy: ',acc)#1/2\n",
    "\n",
    "##test my accuracy function logic\n",
    "scores = torch.randn(2,4)\n",
    "preds = torch.sigmoid(scores).round()\n",
    "print('prediction\\n',preds)\n",
    "truth = (preds==y)#stupid typo here\n",
    "print('truth table\\n',truth)\n",
    "no_correct = truth.float().sum().item()\n",
    "no_correct_attr = truth.float().sum(0)#40-size tensor\n",
    "print( no_correct, no_correct_attr  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. training , saving and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(scores, labels):\n",
    "    preds = torch.sigmoid(scores).round()\n",
    "    truth = (preds==labels)\n",
    "    num_correct = truth.float().sum().item()/40 #avg no of  correct prediction * no of samples\n",
    "    num_correct_attr = truth.float().sum(0)#40-size tensor\n",
    "    return num_correct, num_correct_attr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer,scheduler, epoches=1, test=True):\n",
    "    start = time.time()\n",
    "    \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(0, epoches):\n",
    "\n",
    "        running_loss = train_acc = 0\n",
    "\n",
    "        \n",
    "        for x,y in train_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x.requires_grad_()\n",
    "            s = model(x)\n",
    "            loss = criterion(s,y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.detach().item()*x.size(0)\n",
    "            train_acc += batch_accuracy(s.detach(),y)[0]\n",
    "        running_loss /= len(train_dataset)\n",
    "        train_acc /= len(train_dataset)\n",
    "        print('epoch',epoch+1,'/',epoches, 'time elapsed:%d s '%( time.time()-start))        \n",
    "        print('running loss:', running_loss, 'training accuracy:' , train_acc*100)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if epoch%3 == 0 and test:\n",
    "            with torch.no_grad():\n",
    "                running_loss = val_acc = 0\n",
    "                for x,y in val_loader:\n",
    "                    x,y = x.to(device), y.to(device)\n",
    "                    model.eval()\n",
    "                    s = model(x)\n",
    "                    loss = criterion(s,y.float())\n",
    "\n",
    "                    running_loss += loss.detach().item()*x.size(0)\n",
    "                    val_acc += batch_accuracy(s.detach(),y)[0]\n",
    "                running_loss /= len(val_dataset)\n",
    "                val_acc /= len(val_dataset)\n",
    "                print('validation loss:', running_loss, 'validation accuracy:' , val_acc*100)\n",
    "                    \n",
    "        #copy model weights if test accuracy improves\n",
    "        if val_acc>best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    \n",
    "    print('best accuracy', best_acc*100)\n",
    "\n",
    "    #load best weights\n",
    "    model.load_state_dict(best_weights)\n",
    "    return model            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_evaluation(model, loader=test_loader):\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        running_loss = test_accuracy = 0\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            model.eval()\n",
    "            s = model(x)\n",
    "            loss = criterion(s,y.float())\n",
    "\n",
    "            running_loss += loss.detach().item()*x.size(0)\n",
    "            test_accuracy += batch_accuracy(s.detach(),y)[0]\n",
    "        running_loss /= len(loader.dataset)\n",
    "        test_accuracy /= len(loader.dataset)\n",
    "        print('time elapsed:%d s '%( time.time()-start)) \n",
    "        print('test loss:', running_loss, 'test accuracy:' , test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#only optimize new fc layer\n",
    "optimizer = optim.SGD(model_pt.fc.parameters(), lr = 0.001, momentum=0.9)\n",
    "optimizer_conv = optim.SGD(model_pt.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "#train\n",
    "model_pt.load_state_dict(state_dict0)\n",
    "model = train_model(model_pt, criterion, optimizer_conv, scheduler, epoches=10)\n",
    "# save\n",
    "state_dict = torch.save(model.state_dict(),'checkpoint.pth')\n",
    "# test\n",
    "test_evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# list(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.state_dict()['param_groups'][0]['lr'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model_pt.load_state_dict(state_dict0)\n",
    "# list(model_pt.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Parameter tuning\n",
    "### experiments i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### No. 1: epoch=1\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip\n",
    "- model: resnet18\n",
    "- optimizer: SGD+schedueler, lr=0.001\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(512,40)\n",
    "- epoches: 1\n",
    "- time: 79s\n",
    "- evaluation: <br>test loss: 0.48917443871498106 test accuracy: 79.7625\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No. 2: epoch =10\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip\n",
    "- model: resnet18\n",
    "- optimizer: SGD+schedueler, lr=0.001\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(512,40)\n",
    "- epoches: 10\n",
    "- time: 79s\n",
    "- evaluation: <br>test loss: 0.4280791974067688 test accuracy: 81.625\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No. 3: learning rate 0.01,test>>train? random...\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip\n",
    "- optimizer: lr=0.01\n",
    "- model: resnet18\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(512,40)\n",
    "- epoches: 1\n",
    "- time: 13min\n",
    "- evaluation: <br>\n",
    "epoch 1 / 1 time elapsed:75 s \n",
    "running loss: 0.5641420304775238 training accuracy: 70.19999999999999\n",
    "validation loss: 0.44201597809791565 validation accuracy: 80.375\n",
    "best accuracy 80.375\n",
    "test loss: 0.4328741908073425 test accuracy: 81.5625\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No. 4: Data augmentation: rotation + centercrop\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip +        transforms.RandomRotation(20),    transforms.CenterCrop((178,178)),\n",
    "- optimizer: lr=0.01\n",
    "- model: resnet18\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(512,40)\n",
    "- epoches: 10\n",
    "- time: 13min\n",
    "- evaluation: <br>test loss: 0.43850406527519226 test accuracy: 81.3875\n",
    "- comment: 1st epoch acc: 50%, after 4 epoch reach 80%, then stable..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No. 5: Data augmentation: rotation + randomcrop, similar to no.5\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip +        transforms.RandomRotation(20),    transforms.CenterCrop((178,178)),\n",
    "- optimizer: lr=0.01\n",
    "- model: resnet18\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(512,40)\n",
    "- epoches: 10\n",
    "- time: 13min\n",
    "- evaluation: <br>test loss: 0.44117275953292845 test accuracy: 81.30000000000001\n",
    "- comment: 1st epoch acc: 50%, after 4 epoch reach 80%, then stable...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment ii retrain resnet18+1fc is  best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### No. 6: retrain conv, much better! save as checkpoint6.pth (best efficiency)\n",
    "### Means 1fc layer lacks complexity\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip +        transforms.RandomRotation(20),    transforms.CenterCrop((178,178)),\n",
    "- optimizer: lr=0.01\n",
    "- model: resnet18\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(512,40)\n",
    "- epoches: 10\n",
    "- time: 13min++\n",
    "- evaluation: 1st epoch: validation loss: 0.4332087850570679 validation accuracy: 81.2625\n",
    "\n",
    "test loss: 0.30936500668525696 test accuracy: 86.775"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No. 7: pretrained+deep 2 fc layers +drop out\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip +        transforms.RandomRotation(20),    transforms.CenterCrop((178,178)),\n",
    "- optimizer: lr=0.01\n",
    "- model: resnet18\n",
    "- freeze conv layers: True\n",
    "- fc layer: model_pt.fc = nn.Sequential(nn.Dropout(p=0.2),nn.Linear(in_size,256), nn.ReLU(), nn.Linear(256,4))\n",
    "- epoches: 10&20\n",
    "- time: 15min+ 23min\n",
    "- evaluation: <br> 10epoches: test loss: 0.39907381772994993 test accuracy: 83.71249999999999\n",
    "- 20epoches: test loss: 0.3699471116065979 test accuracy: 83.9875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No. 8: resnet50 +1fc\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip +        transforms.RandomRotation(20),    transforms.CenterCrop((178,178)),\n",
    "- optimizer: lr=0.01\n",
    "- model: resnet18\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(2048,40)\n",
    "- epoches: 3/10\n",
    "- time: 4min/epoch\n",
    "- evaluation: <br>\n",
    "epoch 1 / 10 time elapsed:235 s \n",
    "running loss: 0.5192274848620096 training accuracy: 74.84583333333333\n",
    "validation loss: 0.43311495304107667 validation accuracy: 80.6\n",
    "epoch 2 / 10 time elapsed:551 s \n",
    "running loss: 0.4324911272525787 training accuracy: 81.04166666666666\n",
    "epoch 3 / 10 time elapsed:814 s \n",
    "\n",
    "running loss: 0.4192929100990295 training accuracy: 82.25833333333334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No. 9: resnet50 +dropout(0.5)+1fc\n",
    "- batch_size:32\n",
    "- data augmentation:random horizontal flip +        transforms.RandomRotation(20),    transforms.CenterCrop((178,178)),\n",
    "- optimizer: lr=0.01\n",
    "- model: resnet18\n",
    "- freeze conv layers: True\n",
    "- fc layer: nn.Linear(2048,40)\n",
    "- epoches: 10\n",
    "- time: 5.5min/epoch\n",
    "- evaluation: <br>\n",
    "epoch 1 / 10 time elapsed:332 s \n",
    "running loss: 0.5315309766928354 training accuracy: 73.51666666666668\n",
    "validation loss: 0.4316992115974426 validation accuracy: 81.03750000000002\n",
    "epoch 2 / 10 time elapsed:778 s \n",
    "running loss: 0.4411350138982137 training accuracy: 80.71666666666665\n",
    "epoch 3 / 10 time elapsed:1549 s \n",
    "running loss: 0.4266382654507955 training accuracy: 81.64166666666665"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 5. Generating predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_data = datasets.ImageFolder(root+'/data/', transform = transforms.Compose([\n",
    "        transforms.Resize((178,178)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize]))\n",
    "final_loader = torch.utils.data.DataLoader(final_data, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_random_image(final_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_attributes(model, loader):\n",
    "    state_dict = torch.load('checkpoint6.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        running_loss = test_accuracy = 0\n",
    "        attr_acc = torch.Tensor(40)\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            model.eval()\n",
    "            s = model(x)\n",
    "            loss = criterion(s,y.float())\n",
    "\n",
    "            running_loss += loss.detach().item()*x.size(0)\n",
    "            test_accuracy += batch_accuracy(s.detach(),y)[0]\n",
    "            attr_acc += batch_accuracy(s.detach(),y)[1]\n",
    "        running_loss /= len(loader.dataset)\n",
    "        test_accuracy /= len(loader.dataset)\n",
    "        attr_acc /= len(loader.dataset)        \n",
    "        print('time elapsed:%d s '%( time.time()-start)) \n",
    "        print('test loss:', running_loss, 'test accuracy:' , test_accuracy*100)\n",
    "        print('accuracy per attribute', attr_acc)\n",
    "        \n",
    "        return attr_acc\n",
    "attr_acc = test_attributes(model_pt, test_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rank_attributes = np.argsort(attr_acc)\n",
    "rank_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def output_labels(model, loader):\n",
    "#     state_dict = torch.load('checkpoint0.pth')\n",
    "#     model.load_state_dict(state_dict)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = test_accuracy = 0\n",
    "        arr = torch.Tensor((1,40))\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            model.eval()\n",
    "            s = model(x)\n",
    "            preds = torch.sigmoid(s).round()# prob 0.5 is 1\n",
    "            preds = preds*2 - 1\n",
    "            arr = np.concatenate((arr,preds), axis=0)    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### make prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "labels = output_labels(model_pt, final_loader)\n",
    "np.savetxt(\"predictions.txt\", arr, fmt='%d', footer='\\n', comments='')\n",
    "\n",
    "test_images = '/Users/clairegong/Downloads/ACV Project/data/test_img'\n",
    "img_names = os.listdir(test_images)\n",
    "file = \"predictions.txt\"\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    lines = [' '.join([img, x.strip(), '\\n']) for x,img in zip(f.readlines(),img_names)]\n",
    "\n",
    "with open(file, 'w') as f:\n",
    "    f.writelines(lines) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### check data positive attribute distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#check sample labels for e.g. attribute idx 35 (0-39)\n",
    "attr35 = np.array(test_dataset.targets)[:,35]\n",
    "idx = list(np.where(attr35==1)[0].astype(int))\n",
    "idx\n",
    "\n",
    "## try to take section of data with multiple indices, but can not, dataset is in the form of a list\n",
    "# torch.utils.data.DataLoader(test_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def positive_attributes(dataset):\n",
    "    #dim tip, arr dim is (200,40), put 0/row then calculation cross 200 rows, result size will be same as dim 1-> 40\n",
    "    distribution = np.array(dataset.targets).sum(0)\n",
    "    sort_idx = np.argsort(distribution)+1\n",
    "    print('for {} samples, min num {} for attribute {} and max num {} for attribute {}'.format(len(dataset),distribution.min(), sort_idx[0],\\\n",
    "                                                                               distribution.max(), sort_idx[-1]))\n",
    "    return sort_idx\n",
    "#     return distribution\n",
    "\n",
    "print(positive_attributes(train_dataset))\n",
    "print(positive_attributes(val_dataset))\n",
    "print(positive_attributes(test_dataset))\n",
    "\n",
    "##check no of labels per person have\n",
    "# plt.hist(np.array(train_dataset.targets).sum(1),bins=17);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference: attribute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import IPython.display as Disp\n",
    "url = 'https://www.researchgate.net/publication/327029519/figure/tbl1/AS:667628372766726@1536186416689/List-of-the-40-face-attributes-provided-with-the-CelebA-database.png'\n",
    "Disp.Image(requests.get(url).content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv('/Users/clairegong/Downloads/list_attr_celeba.txt', sep=' ', header=None)\n",
    "accuracies = [0.9482, 0.8340, 0.8293, 0.8538, 0.9893, 0.9600, 0.7152, 0.8398, 0.9002,\n",
    "        0.9596, 0.9632, 0.8904, 0.9260, 0.9589, 0.9639, 0.9962, 0.9744, 0.9833,\n",
    "        0.9184, 0.8758, 0.9813, 0.9377, 0.9696, 0.8766, 0.9619, 0.7556, 0.9706,\n",
    "        0.7684, 0.9381, 0.9504, 0.9775, 0.9283, 0.8448, 0.8488, 0.9031, 0.9904,\n",
    "        0.9385, 0.8739, 0.9682, 0.8886]\n",
    "attributes.loc[1] = accuracies\n",
    "attributes = attributes.T\n",
    "attributes.columns=['attr','acc']\n",
    "attributes['acc'] = attributes['acc'].astype('float64') *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes = attributes.sort_values(by='acc', ascending=False).round(1).reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# di = dict(zip(attributes['attr'], attributes['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path1 = '/Users/clairegong/Downloads/predictions_1020_2am.txt'\n",
    "path2 = '/Users/clairegong/Downloads/predictions_1021_2pm.txt'\n",
    "path3 = '/Users/clairegong/Downloads/predictions_1021_4pm.txt'#removed space in last col\n",
    "ref1 = '/Users/clairegong/Downloads/prediction_utsa.txt'\n",
    "ref2 = '/Users/clairegong/Downloads/predictions_vakul.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pd.read_csv(path1, sep=' ', header=None).drop([41], axis=1)\n",
    "pred2 = pd.read_csv(path2, sep=' ', header=None).drop([41], axis=1)\n",
    "pred3 = pd.read_csv(path3, sep=' ', header=None)\n",
    "ref1 = pd.read_csv(ref1, sep=' ', header=None)\n",
    "ref2 = pd.read_csv(ref2, sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8914520793360281"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with utsa\n",
    "(pred2==ref1).mean().mean()\n",
    "(pred3==ref1).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8540179484769229"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with vakul\n",
    "(pred2==ref2).mean().mean()\n",
    "(pred2==ref2).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "print(str(x)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = list(attributes['attr'])\n",
    "attr.insert(0, 'img')\n",
    "pred.columns=attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1541</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blond_Hair</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No_Beard</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smiling</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1541\n",
       "Blond_Hair          1\n",
       "No_Beard            1\n",
       "Smiling             1\n",
       "Wavy_Hair           1\n",
       "Wearing_Lipstick    1\n",
       "Young               1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check image labels\n",
    "name = 'Bridgette_Wilson-Sampras_0001.jpg'\n",
    "truth = pred[pred.img==name].T == 1\n",
    "pred[pred.img==name].T[truth].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
